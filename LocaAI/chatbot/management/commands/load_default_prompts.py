from django.core.management.base import BaseCommand
from chatbot.models import Prompt


class Command(BaseCommand):
    help = 'í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.'

    def add_arguments(self, parser):
        parser.add_argument(
            '--update',
            action='store_true',
            help='ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.',
        )

    def handle(self, *args, **options):
        update_existing = options['update']
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì •ì˜
        default_prompts = [
            # RAG ì‘ë‹µ ì¡°í•© í”„ë¡¬í”„íŠ¸ë“¤
            {
                'name': 'rag_combine_answers_ko',
                'scope': 'collection',
                'content': """ë‹¤ìŒì€ ì—¬ëŸ¬ ì¶œì²˜ì˜ ë‹µë³€ì…ë‹ˆë‹¤:

{answers}

ìœ„ì˜ ì—¬ëŸ¬ ë‹µë³€ë“¤ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ìµœì¢… ìš”ì•½ëœ ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ê° ì¶œì²˜ì˜ í•µì‹¬ ì •ë³´ë¥¼ í†µí•©í•˜ê³ , ì¼ê´€ì„± ìˆê³  ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”.""",
                'tag': 'rag,combine,korean'
            },
            {
                'name': 'rag_combine_answers_en',
                'scope': 'collection',
                'content': """Based on the following multiple sources:

{answers}

Please synthesize the above answers to provide a final, comprehensive summary that will be helpful to the user. Integrate key information from each source and provide a consistent and clear response.""",
                'tag': 'rag,combine,english'
            },
            {
                'name': 'rag_combine_answers_es',
                'scope': 'collection',
                'content': """Basado en las siguientes fuentes mÃºltiples:

{answers}

Por favor, sintetiza las respuestas anteriores para proporcionar un resumen final y completo que sea Ãºtil para el usuario. Integra la informaciÃ³n clave de cada fuente y proporciona una respuesta consistente y clara.""",
                'tag': 'rag,combine,spanish'
            },
            
            # LLM ìƒë‹´ í”„ë¡¬í”„íŠ¸ë“¤
            {
                'name': 'llm_consultation',
                'scope': 'user',
                'content': """ë‹¹ì‹ ì€ ìƒê¶Œ ë¶„ì„ ë° ì°½ì—… ìƒë‹´ ì „ë¬¸ AIì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ì™€ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ìƒë‹´ì„ ì œê³µí•´ì£¼ì„¸ìš”.

## ì—­í• 
- ìƒê¶Œ ë¶„ì„ ì „ë¬¸ê°€
- ì°½ì—… ë° ì‚¬ì—… ìš´ì˜ ì»¨ì„¤í„´íŠ¸
- ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ ì œê³µì

## ë‹µë³€ ì›ì¹™
1. ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ
2. êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ìˆ˜ì¹˜ê°€ ì—†ë”ë¼ë„ ì¼ë°˜ì ì¸ ì—…ê³„ ì§€ì‹ê³¼ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
3. ì‚¬ìš©ìì˜ ìƒí™©ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì¡°ì–¸
4. ê°€ëŠ¥í•œ ìœ„í—˜ ìš”ì†Œë‚˜ ì£¼ì˜ì‚¬í•­ë„ í•¨ê»˜ ì•ˆë‚´
5. ì¶”ê°€ì ì¸ ì •ë³´ ìˆ˜ì§‘ì´ë‚˜ ì „ë¬¸ê°€ ìƒë‹´ì´ í•„ìš”í•œ ê²½ìš° ì•ˆë‚´

ì§ˆë¬¸: {question}

ëŒ€í™” íˆìŠ¤í† ë¦¬:
{chat_history}

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìƒê¶Œ ë¶„ì„, ì°½ì—…, ì‚¬ì—… ìš´ì˜ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ ì£¼ì„¸ìš”.""",
                'tag': 'llm,consultation,korean,business'
            },
            {
                'name': 'llm_consultation_en',
                'scope': 'user',
                'content': """You are a professional AI consultant specializing in commercial area analysis and business consulting. Please provide expert consultation based on the information and questions provided by the user.

## Role
- Commercial area analysis expert
- Business startup and operations consultant
- Provider of practical and specific advice

## Response Principles
1. Provide professional and practical advice
2. Give helpful answers based on general industry knowledge and experience, even without specific data or figures
3. Provide customized advice considering the user's situation
4. Also guide potential risk factors or precautions
5. Guide when additional information gathering or professional consultation is needed

Question: {question}

Chat History:
{chat_history}

Based on the above content, please provide professional and practical advice on commercial area analysis, business startup, and business operations.""",
                'tag': 'llm,consultation,english,business'
            },
            {
                'name': 'llm_consultation_es',
                'scope': 'user',
                'content': """Eres un consultor de IA profesional especializado en anÃ¡lisis de Ã¡reas comerciales y consultorÃ­a empresarial. Proporciona consultorÃ­a experta basada en la informaciÃ³n y preguntas proporcionadas por el usuario.

## Rol
- Experto en anÃ¡lisis de Ã¡reas comerciales
- Consultor de inicio de negocios y operaciones
- Proveedor de consejos prÃ¡cticos y especÃ­ficos

## Principios de Respuesta
1. Proporcionar consejos profesionales y prÃ¡cticos
2. Dar respuestas Ãºtiles basadas en conocimiento general de la industria y experiencia, incluso sin datos o cifras especÃ­ficas
3. Proporcionar consejos personalizados considerando la situaciÃ³n del usuario
4. TambiÃ©n guiar sobre factores de riesgo potenciales o precauciones
5. Orientar cuando se necesite recopilaciÃ³n de informaciÃ³n adicional o consulta profesional

Pregunta: {question}

Historial de chat:
{chat_history}

Basado en el contenido anterior, proporciona consejos profesionales y prÃ¡cticos sobre anÃ¡lisis de Ã¡reas comerciales, creaciÃ³n de empresas y operaciones comerciales.""",
                'tag': 'llm,consultation,spanish,business'
            },
        ]

        created_count = 0
        updated_count = 0
        skipped_count = 0

        for prompt_data in default_prompts:
            try:
                prompt, created = Prompt.objects.get_or_create(
                    name=prompt_data['name'],
                    defaults={
                        'scope': prompt_data['scope'],
                        'content': prompt_data['content'],
                        'tag': prompt_data['tag']
                    }
                )
                
                if created:
                    created_count += 1
                    self.stdout.write(
                        self.style.SUCCESS(f"âœ… ìƒˆ í”„ë¡¬í”„íŠ¸ ìƒì„±: {prompt_data['name']}")
                    )
                elif update_existing:
                    # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
                    prompt.scope = prompt_data['scope']
                    prompt.content = prompt_data['content']
                    prompt.tag = prompt_data['tag']
                    prompt.save()
                    updated_count += 1
                    self.stdout.write(
                        self.style.WARNING(f"ğŸ”„ ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸: {prompt_data['name']}")
                    )
                else:
                    skipped_count += 1
                    self.stdout.write(
                        self.style.HTTP_INFO(f"â­ï¸  ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ê±´ë„ˆëœ€: {prompt_data['name']}")
                    )
                    
            except Exception as e:
                self.stdout.write(
                    self.style.ERROR(f"âŒ í”„ë¡¬í”„íŠ¸ '{prompt_data['name']}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                )

        # ê²°ê³¼ ìš”ì•½
        self.stdout.write("\n" + "="*50)
        self.stdout.write(self.style.SUCCESS(f"ğŸ“Š ì‘ì—… ì™„ë£Œ ìš”ì•½:"))
        self.stdout.write(f"  â€¢ ìƒˆë¡œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {created_count}ê°œ")
        self.stdout.write(f"  â€¢ ì—…ë°ì´íŠ¸ëœ í”„ë¡¬í”„íŠ¸: {updated_count}ê°œ")
        self.stdout.write(f"  â€¢ ê±´ë„ˆë›´ í”„ë¡¬í”„íŠ¸: {skipped_count}ê°œ")
        self.stdout.write("="*50)
        
        if created_count > 0 or updated_count > 0:
            self.stdout.write(
                self.style.SUCCESS(
                    f"\nğŸ‰ ì´ {created_count + updated_count}ê°œì˜ í”„ë¡¬í”„íŠ¸ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!"
                )
            )
            self.stdout.write("ğŸ’¡ Django Admin í˜ì´ì§€ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            self.stdout.write(
                self.style.HTTP_INFO(
                    "\nğŸ’¡ ëª¨ë“  ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. --update ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
            ) 